{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YouTube Audio Download and Transcription Script\n",
        "This script downloads audio from YouTube videos, transcribes it using OpenAI's Whisper model, and saves the transcriptions to a CSV file. It’s designed for bulk processing, allowing concurrent downloads and transcriptions for faster results.\n",
        "\n",
        "# User Requirements:\n",
        "\n",
        "###Input CSV:\n",
        "Prepare a CSV file with YouTube video URLs and titles (e.g., video_data.csv). Upload this file to Google Drive and specify its path in the code at csv_input_path.\n",
        "\n",
        "###Output Location:\n",
        "Set the output_path to a folder in Google Drive where you want to save the final CSV file containing the transcriptions.\n",
        "This script will:\n",
        "\n",
        "Download each video’s audio, transcribe it, and remove the audio file after transcription.\n",
        "Save the transcription results in a CSV file, which is stored in your specified Google Drive location."
      ],
      "metadata": {
        "id": "wiEB9v2_wX3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install what we need, just press play"
      ],
      "metadata": {
        "id": "1r6rjdLhw3T2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXNEn9dYuJkl"
      },
      "outputs": [],
      "source": [
        "!pip install pytubefix\n",
        "!pip install pafy\n",
        "!pip install -U yt-dlp\n",
        "!pip install -U moviepy openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connect your google drive\n",
        "\n",
        "This code is essential because it mounts your Google Drive to the Colab environment, allowing the notebook to access files stored in your Drive.\n",
        "Follow the instructions."
      ],
      "metadata": {
        "id": "B9CumtE6w-7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LkAbhczCuW7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code Function\n",
        "This code downloads audio from YouTube videos, transcribes it using OpenAI's Whisper model, and saves the transcriptions in a CSV file in Google Drive.\n",
        "\n",
        "###User Instructions\n",
        "Before running the code, go through each section and check for lines marked as # ===== USER ACTION REQUIRED =====. These are lines where you need to provide input or make adjustments for the script to run correctly.\n",
        "\n",
        "###The user is required to:\n",
        "\n",
        "* Specify the Input CSV Path: Update csv_input_path to point to the location of your CSV file in Google Drive. This file should contain the YouTube video URLs and titles.\n",
        "\n",
        "* Set the Output Path: Modify output_path to specify where you want the final CSV with transcriptions saved in your Google Drive.\n",
        "\n",
        "* Ensure Drive Mounting and Folder Setup: Run the code to mount Google Drive, and confirm that your input file is uploaded and accessible at the specified path.\n",
        "\n",
        "\n",
        "###Important Reminders\n",
        "Run Time: If you have a large number of files or are running on a CPU, this process may take considerable time. Colab’s free tier has limited resources and can time out if left inactive or if your computer shuts down.\n",
        "Upgrade for Better Performance: Consider using Colab Pro for access to faster GPUs, such as the A100, which can significantly reduce processing time. The A100 GPU is powerful and well-suited for intensive tasks like transcription.\n",
        "\n",
        "Output: As the code runs, you’ll see messages for each video, indicating when the audio is downloading, transcribing, and when the process is complete for each video."
      ],
      "metadata": {
        "id": "Qc8wPMrBxwx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp  # YouTube downloader\n",
        "import os\n",
        "import whisper  # Whisper model for transcription\n",
        "from concurrent.futures import ThreadPoolExecutor  # For concurrent processing\n",
        "import warnings\n",
        "import pandas as pd\n",
        "\n",
        "# Suppress specific warnings to keep the output clean\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Function to download audio from YouTube using yt_dlp\n",
        "def download_audio(url, title, output_folder):\n",
        "    print(f\"Downloading audio: {title} from {url}\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': f'{output_folder}/{title}.%(ext)s',\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "        'noplaylist': True,\n",
        "        'quiet': True,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        return f\"{output_folder}/{title}.wav\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {title}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to transcribe audio using Whisper\n",
        "def transcribe_audio(audio_path):\n",
        "    if audio_path is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        model = whisper.load_model(\"base\")\n",
        "        transcription = model.transcribe(audio_path)\n",
        "        return transcription['text']\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to handle downloading and transcribing a single row (video)\n",
        "def download_and_transcribe(row):\n",
        "    url = row['link']\n",
        "    title = row['title']\n",
        "\n",
        "    # Download audio\n",
        "    audio_path = download_audio(url, title, output_folder)\n",
        "\n",
        "    # Transcribe audio\n",
        "    transcription = transcribe_audio(audio_path)\n",
        "    row['transcription'] = transcription\n",
        "\n",
        "    # Remove the audio file after transcription to save storage\n",
        "    if audio_path and os.path.exists(audio_path):\n",
        "        os.remove(audio_path)\n",
        "        print(f\"Deleted audio file: {audio_path}\")\n",
        "\n",
        "    return transcription\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Define paths\n",
        "    output_folder = \"youtube_mp4\"  # Temporary folder for downloaded audio files\n",
        "    output_path = '/content/drive/My Drive/your_output_folder/output_with_transcriptions.csv'  # Final CSV path in Google Drive\n",
        "\n",
        "    # ===== USER ACTION REQUIRED =====\n",
        "    # Set the path to the CSV file containing the video links and titles\n",
        "    # Make sure this CSV file (e.g., 'video_data.csv') is uploaded to your Google Drive and replace the path below\n",
        "    csv_input_path = \"/content/drive/My Drive/your_input_folder/video_data.csv\"\n",
        "\n",
        "    # Ensure output and input folder paths are accessible and correct\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Load your CSV file with video data\n",
        "    try:\n",
        "        df = pd.read_csv(csv_input_path)  # Load CSV file containing video URLs and titles\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {csv_input_path} was not found. Please check the file path and ensure it is uploaded to Google Drive.\")\n",
        "        raise\n",
        "\n",
        "    # Process each video concurrently\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        futures = {executor.submit(download_and_transcribe, row): row for _, row in df.iterrows()}\n",
        "        for future in futures:\n",
        "            row = futures[future]\n",
        "            try:\n",
        "                future.result()  # Wait for each future to complete\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {row['title']}: {e}\")\n",
        "\n",
        "    print(\"Processing complete.\")\n",
        "\n",
        "\n",
        "    # Save the final DataFrame, including transcriptions, to a CSV file\n",
        "    df.to_csv(output_path, index=False)  # This saves the output CSV with the transcriptions\n",
        "    print(f\"Final output saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "hw-bv6_buiiW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}